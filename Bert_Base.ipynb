{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification,BertModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import ast\n",
    "from seqeval.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from google.colab import drive\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# drive.mount('/content/drive')\n",
    "data=pd.read_csv(\"/content/drive/MyDrive/google_upload/revised_tags_2.csv\")\n",
    "# data=data[[\"tokens\",\"ner_tokens\"]].drop_duplicates()\n",
    "data[\"tokens\"]=data[\"tokens\"].apply(lambda x:ast.literal_eval(x))\n",
    "data[\"ner_tokens\"]=data[\"ner_tokens\"].apply(lambda x:ast.literal_eval(x))\n",
    "id2label={0: 'O',\n",
    "        1: 'B-method',\n",
    "        2: 'I-method',\n",
    "        3: 'B-material',\n",
    "        4: 'I-material',\n",
    "        5: 'B-product',\n",
    "        6: 'I-product',\n",
    "        7: 'B-Faradaicefficiency',\n",
    "        8: 'I-Faradaicefficiency'\n",
    "        }\n",
    "\n",
    "label2id={v:k for k,v in id2label.items()}\n",
    "\n",
    "\n",
    "# Dataset Loader\n",
    "\n",
    "max_len=110\n",
    "model_name=\"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer=BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "class dataset(Dataset):\n",
    "  def __init__(self,df,tokenizer,max_len):\n",
    "    self.df=df\n",
    "    self.len=len(df)\n",
    "    self.max_len=max_len\n",
    "    self.tokens=df[\"tokens\"]\n",
    "    self.ner_tokens=df[\"ner_tokens\"]\n",
    "    self.tokenizer=tokenizer\n",
    "  def __getitem__(self,index):\n",
    "    tokens=self.tokens.iloc[index]\n",
    "    ner_tokens=self.ner_tokens.iloc[index]\n",
    "    tokenized_data=self.tokenizer(tokens,\n",
    "                                  is_split_into_words=True,\n",
    "                                  return_offsets_mapping=True,\n",
    "                                  padding=\"max_length\",\n",
    "                                  truncation=True,\n",
    "                                  max_length=self.max_len)\n",
    "    encoded_labels=np.ones(len(tokenized_data[\"offset_mapping\"]),dtype=int)*-100\n",
    "    i=0\n",
    "    for idx,mapping in enumerate(tokenized_data[\"offset_mapping\"]):\n",
    "      if mapping[0]==0 and mapping[1]!=0:\n",
    "        encoded_labels[idx]=ner_tokens[i]\n",
    "        i+=1\n",
    "    items={k:torch.as_tensor(v) for k,v in tokenized_data.items()}\n",
    "    items[\"labels\"]=torch.as_tensor(encoded_labels)\n",
    "    return items\n",
    "  def __len__(self):\n",
    "      return self.len\n",
    "\n",
    "train_size = 0.8\n",
    "X=data[[\"tokens\"]]\n",
    "y=data[[\"ner_tokens\"]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_vt, y_train, y_vt =train_test_split(X,y,train_size=train_size,random_state=42)\n",
    "X_test,X_valid,y_test,y_valid=train_test_split(X_vt,y_vt,train_size=0.5,random_state=42)\n",
    "def rejoint(x,y):\n",
    "  df=pd.concat([x,y],axis=1)\n",
    "  return df\n",
    "train_dataset = rejoint(X_train,y_train)\n",
    "test_dataset = rejoint(X_test,y_test)\n",
    "val_dataset = rejoint(X_valid,y_valid)\n",
    "train_data=dataset(train_dataset,tokenizer,max_len)\n",
    "val_data=dataset(val_dataset,tokenizer,max_len)\n",
    "test_data=dataset(test_dataset,tokenizer,max_len)\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "full_data=pd.concat([train_dataset,val_dataset,test_dataset])\n",
    "\n",
    "all_tokens=[]\n",
    "full_data[\"ner_tokens\"].apply(lambda x:all_tokens.extend(x))\n",
    "unique_labels=np.unique(all_tokens)\n",
    "class_weights=compute_class_weight(class_weight=\"balanced\",classes=unique_labels,y=all_tokens)\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BERT Base\n",
    "## Parameters\n",
    "TRAIN_BATCH_SIZE=24\n",
    "TEST_BATCH_SIZE=12\n",
    "VALID_BATCH_SIZE=12\n",
    "\n",
    "## Training Control\n",
    "EPOCHS=4\n",
    "LEARNING_RATE=0.8e-04\n",
    "MAX_GRAD_NORM=5\n",
    "WARMUP=0.1\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "val_params =  {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "training_loader=DataLoader(train_data,**train_params)\n",
    "test_loader=DataLoader(test_data,**test_params)\n",
    "val_loader=DataLoader(val_data,**val_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNER(nn.Module):\n",
    "  def __init__(self,model_name,num_labels,device,class_weights=None): #Initialising model layers\n",
    "    super(BNER,self).__init__()\n",
    "    self.device=device\n",
    "    self.bert=BertModel.from_pretrained(model_name,config=BertConfig.from_pretrained(model_name,num_labels=num_labels)).to(device)\n",
    "    self.num_labels=num_labels\n",
    "    self.dropout=nn.Dropout(0.3)\n",
    "    self.classifier=nn.Linear(768,num_labels,device=device) #Inputs BERT encodings and outputs classification logits\n",
    "    if class_weights==None: # Implementing class weights if desired\n",
    "      self.loss_func=nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    else:\n",
    "      self.loss_func=nn.CrossEntropyLoss(ignore_index=-100,weight=class_weights)\n",
    "\n",
    "  def forward(self,input_ids,attention_mask=None,labels=None):\n",
    "    hidden_state_output=self.bert(input_ids,attention_mask=attention_mask)#Bert models output batch size x max_sequence_length x 768\n",
    "    hidden_state=hidden_state_output[0]\n",
    "    sequence_outputs=self.dropout(hidden_state)\n",
    "    logits=self.classifier(sequence_outputs.view(-1,768)) #Reduces encodings to dimension 9\n",
    "    output={\"logits\":logits}\n",
    "    if labels != None:\n",
    "      flattened_labels=labels.view(-1)\n",
    "      loss=self.loss_func(logits,flattened_labels)\n",
    "      output[\"loss\"]=loss\n",
    "      return output\n",
    "## Training Requirements\n",
    "TRAIN_STEPS=EPOCHS*len(training_loader)\n",
    "VAL_STEPS=EPOCHS*len(val_loader)\n",
    "TEST_STEPS=EPOCHS*len(test_loader)\n",
    "num_warmup_steps=int(WARMUP*TRAIN_STEPS)\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "class_weights=class_weights.to(device)\n",
    "num_labels=len(label2id.keys())\n",
    "model=BNER(model_name=model_name,num_labels=num_labels,device=device,class_weights=class_weights)\n",
    "model.to(device)\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=LEARNING_RATE)\n",
    "scheduler=get_cosine_schedule_with_warmup(optimizer,num_warmup_steps,TRAIN_STEPS)\n",
    "\n",
    "# Validating model function before training\n",
    "\n",
    "inputs = train_data[3]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "outputs[\"loss\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training and Evaluation Functions\n",
    "\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "metric = load_metric(\"seqeval\")\n",
    "def eval(model,eval_loader,return_output=True):\n",
    "    # prog_bar=tqdm(total=len(eval_loader),desc=\"eval_steps\",units=\"steps\")\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(eval_loader):\n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long) \n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels) #Runs our model and outputs loss and logits\n",
    "            loss=outputs[\"loss\"]\n",
    "            eval_logits=outputs[\"logits\"]\n",
    "            eval_loss += loss.item()\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape = (batch_size x seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape = (batch_size x seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape = (batch_size x seq_len,)\n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            eval_labels.append(labels.tolist())\n",
    "            eval_preds.append(predictions.tolist())\n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    labels = [[id2label[id] for id in eval_set] for eval_set in eval_labels]\n",
    "    predictions = [[id2label[id] for id in eval_set] for eval_set in eval_preds]\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss} Validation Accuracy: {eval_accuracy}\")\n",
    "    if return_output:\n",
    "      return labels,predictions\n",
    "def get_metrics(lab,pred,return_df=False,hide_display=False):\n",
    "\n",
    "  results=metric.compute(predictions=pred,references=lab) # Runs performance calculations using the predictions and labels\n",
    "  flattened_results = {\n",
    "      \"overall_precision\": results[\"overall_precision\"],\n",
    "      \"overall_recall\": results[\"overall_recall\"],\n",
    "      \"overall_f1\": results[\"overall_f1\"],\n",
    "      \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "  }\n",
    "  clasif={}\n",
    "  for k in results.keys():\n",
    "    if(k not in flattened_results.keys()):\n",
    "      clasif[k]=results[k]\n",
    "  entity_scores=pd.DataFrame(clasif) # Gets the entity level performance scores\n",
    "  overall=pd.DataFrame(flattened_results,index=[\"Total\"])\n",
    "  if not hide_display:\n",
    "    display(entity_scores,overall)\n",
    "  if return_df:\n",
    "    return {\"overall_performance\":overall,\"entity_performance\":entity_scores}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch,log_steps=50,writer=None):\n",
    "\n",
    "  prog_bar=tqdm(total=len(training_loader),desc=f\"Epoch: {epoch+1} training_steps\",unit=\"steps\")\n",
    "  tr_loss=0\n",
    "  nb_tr_examples,nb_tr_steps=0,0\n",
    "  tr_preds,tr_labels=[],[]\n",
    "  model.train()\n",
    "\n",
    "  for idx, batch in enumerate(training_loader):\n",
    "    ids=batch[\"input_ids\"].to(device,dtype=torch.long)\n",
    "    attention=batch[\"attention_mask\"].to(device,dtype=torch.long)\n",
    "    labels=batch[\"labels\"].to(device,dtype=torch.long)\n",
    "    loss=model(input_ids=ids,attention_mask=attention,labels=labels)[\"loss\"]\n",
    "    tr_loss+=loss.item()\n",
    "    nb_tr_steps +=1\n",
    "    nb_tr_examples+=labels.size(0)\n",
    "    if idx % log_steps == 0:\n",
    "      loss_step=tr_loss/nb_tr_steps\n",
    "      print(f\"Training Loss at {nb_tr_steps} training steps:{loss_step}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "      if p.grad is not None:\n",
    "        param_norm = p.grad.data.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "\n",
    "    if writer is not None:\n",
    "      writer.add_scalar('Gradient Norm', total_norm, epoch * len(training_loader) + idx)\n",
    "\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(parameters=model.parameters(),max_norm=MAX_GRAD_NORM)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    prog_bar.update(1)\n",
    "  epoch_loss=tr_loss/nb_tr_steps\n",
    "  print(f\"Training loss at {epoch+1} : {epoch_loss}\")\n",
    "  prog_bar.close()\n",
    "  if writer is not None:\n",
    "    writer.add_scalar('Epoch Loss', epoch_loss, epoch)\n",
    "\n",
    "def plot_confusion_matrix(labels,predictions):\n",
    "  true_labels_flattened=[item for sublist in labels for item in sublist]\n",
    "  true_predictions_flattened=[item for sublist in predictions for item in sublist]\n",
    "  true_labels_flattened=[label2id[id] for id in true_labels_flattened]\n",
    "  true_predictions_flattened=[label2id[id] for id in true_predictions_flattened]\n",
    "\n",
    "  cm=confusion_matrix(true_labels_flattened,true_predictions_flattened)\n",
    "\n",
    "  cm_normalized=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "  fig, ax = plt.subplots()\n",
    "  sns.heatmap(cm_normalized,annot=True,fmt='.2f',cmap='crest',xticklabels=list(label2id.keys()),yticklabels=list(label2id.keys()))\n",
    "  plt.title('Normalized Confusion Matrix')\n",
    "  plt.ylabel('True label')\n",
    "  plt.xlabel('Predicted label')\n",
    "  ax.set_xticklabels(ax.get_xticklabels(), rotation=45,fontdict={\"fontsize\":7})\n",
    "  ax.set_yticklabels(ax.get_yticklabels(),fontdict={\"fontsize\":7})\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer = SummaryWriter(log_dir=\"logs-BERT\")\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "  print(f\"##### TRAINING EPOCH : {i+1} #####\")\n",
    "  train(i,log_steps=20,writer=writer)\n",
    "  eval(model,val_loader,return_output=False)\n",
    "labels,predictions=eval(model,test_loader)\n",
    "get_metrics(labels,predictions)\n",
    "plot_confusion_matrix(labels,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "#removes the log folder\n",
    "%tensorboard --logdir=logs-BERT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standardbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
